{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "538144c0-6592-447b-9f7e-e3eee6faae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint as pp\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e826779c-d0c1-499d-82b6-17a3f37db1c9",
   "metadata": {},
   "source": [
    "# 20210629_lccf\n",
    "\n",
    "----\n",
    "\n",
    "The purpose of this notebook is to generate test data for LCCF performance scaling experiments on the model run in the script `scripts/20210623_lccf.py`.\n",
    "\n",
    "In this notebook, I will load files `data/lccf/*.csv` and cp the rows to emulate large-scale Safegraph data ingests. The starting point of this notebook looks like:\n",
    "\n",
    "```bash\n",
    "$ ls ../data/lccf\n",
    "census_pop1_rows1.csv   contacts_pop1_rows1.csv travel_pop1_rows1.csv\n",
    "```\n",
    "\n",
    "The goal is to make `*rows2.csv`, `*rows4.csv`, etc. files that have 2x, 4x, etc. as many rows as the `*rows1.csv` files.\n",
    "\n",
    "----\n",
    "\n",
    "To test performance scaling as a function of population size, I will also make `*_pop2_rows0.csv`, `*_pop4_rows0.csv`, etc. which are equivalent to `*rows0.csv`, but with 2x, 4x, etc. greater contact/travel/census population. `pop1` is implied if no `pop` identifier is included in the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea6dea5-86aa-4469-b808-19cbbce78517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "census_pop1_rows1.csv   contacts_pop1_rows1.csv travel_pop1_rows1.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/lccf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b8444e-de8a-491f-871f-ca9b11d9da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scaled_df(ref_df: pd.DataFrame, pop_mult=1, rows_mult=1, schema=None) -> pd.DataFrame:\n",
    "    \"\"\"Returns a population or row scaled DataFrame, given a reference dataframe `ref_df`\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfb0812-ac89-4ca9-b654-2285d5adcd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas = {\n",
    "    'census': {\n",
    "        'value_col': None,\n",
    "        'usecols': (\"GEOID\", \"age_bin\", \"group_pop\"),\n",
    "        'glob': list(),\n",
    "        'keys': None\n",
    "    },\n",
    "    'contacts': {\n",
    "        'value_col': None,\n",
    "        'usecols': ('age1', 'age2', 'daily_per_capita_contacts'),\n",
    "        'glob': list(),\n",
    "        'keys': None\n",
    "    },\n",
    "    'travel': {\n",
    "        'value_col': None,\n",
    "        'usecols': ('source', 'destination', 'age', 'n', 'date', 'destination_type'),\n",
    "        'glob': list(),\n",
    "        'keys': None\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8384275-8826-4bd3-9c6e-8de0b41832de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scaled_csvs(dir_fp: str, scales: tuple = (2, 4, 8), verbose=2):\n",
    "    assert os.path.isdir(dir_fp)\n",
    "    for schema in schemas:\n",
    "        query = f\"{schema}*.csv\"\n",
    "        hits = glob(os.path.join(dir_fp, query))\n",
    "        assert len(hits) == 1, f\"found {len(hits)} hits for glob query {query}, expected 1\"\n",
    "        schemas[schema]['glob'] = hits\n",
    "    if verbose:\n",
    "        print(f'schemas:')\n",
    "        pp(schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73e63ac-af90-454e-b20c-638c5644626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schemas:\n",
      "{'census': {'glob': ['../data/lccf/census_pop1_rows1.csv'],\n",
      "            'keys': None,\n",
      "            'usecols': ('GEOID', 'age_bin', 'group_pop'),\n",
      "            'value_col': None},\n",
      " 'contacts': {'glob': ['../data/lccf/contacts_pop1_rows1.csv'],\n",
      "              'keys': None,\n",
      "              'usecols': ('age1', 'age2', 'daily_per_capita_contacts'),\n",
      "              'value_col': None},\n",
      " 'travel': {'glob': ['../data/lccf/travel_pop1_rows1.csv'],\n",
      "            'keys': None,\n",
      "            'usecols': ('source',\n",
      "                        'destination',\n",
      "                        'age',\n",
      "                        'n',\n",
      "                        'date',\n",
      "                        'destination_type'),\n",
      "            'value_col': None}}\n"
     ]
    }
   ],
   "source": [
    "create_scaled_csvs('../data/lccf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421179f-b039-4aac-90f0-f029c73f3565",
   "metadata": {},
   "source": [
    "**Question**: what should we use as the `value_col` for each schema? Also gives us a reminder of what the schema is. Let's `head`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbcabf68-97aa-4c15-86fe-72c2370c69cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ../data/lccf/census_pop1_rows1.csv <==\n",
      "\"\",\"GEOID\",\"NAME\",\"age_bin\",\"group_pop\"\n",
      "\"1\",\"75001\",\"ZCTA5 75001\",\"<5\",794\n",
      "\"2\",\"75001\",\"ZCTA5 75001\",\"18-49\",9420\n",
      "\"3\",\"75001\",\"ZCTA5 75001\",\"5-17\",1404\n",
      "\"4\",\"75001\",\"ZCTA5 75001\",\"50-64\",2259\n",
      "\"5\",\"75001\",\"ZCTA5 75001\",\"65+\",1115\n",
      "\"6\",\"75002\",\"ZCTA5 75002\",\"<5\",4227\n",
      "\"7\",\"75002\",\"ZCTA5 75002\",\"18-49\",29659\n",
      "\"8\",\"75002\",\"ZCTA5 75002\",\"5-17\",15710\n",
      "\"9\",\"75002\",\"ZCTA5 75002\",\"50-64\",14706\n",
      "\n",
      "==> ../data/lccf/contacts_pop1_rows1.csv <==\n",
      ",age1,age2,daily_per_capita_contacts\n",
      "0,<5,<5,2.160940833918119\n",
      "1,5-17,<5,0.5973413405271149\n",
      "2,18-49,<5,0.3822025191217617\n",
      "3,50-64,<5,0.3523966597811896\n",
      "4,65+,<5,0.18975609071541075\n",
      "5,<5,5-17,2.164117384279739\n",
      "6,5-17,5-17,8.146970087503425\n",
      "7,18-49,5-17,2.431391745980527\n",
      "8,50-64,5-17,1.885100325362032\n",
      "\n",
      "==> ../data/lccf/travel_pop1_rows1.csv <==\n",
      ",Unnamed: 0,source,destination,age,n,date,destination_type\n",
      "30555,30555,76511,76511,<5,35.05384615384615,2020-03-11,local\n",
      "30556,30556,76511,76511,18-49,472.2846153846154,2020-03-11,local\n",
      "30557,30557,76511,76511,5-17,150.01538461538462,2020-03-11,local\n",
      "30558,30558,76511,76511,50-64,165.46923076923076,2020-03-11,local\n",
      "30559,30559,76511,76511,65+,121.36923076923075,2020-03-11,local\n",
      "30560,30560,76511,76530,<5,3.576923076923077,2020-03-11,local\n",
      "30561,30561,76511,76530,18-49,48.19230769230769,2020-03-11,local\n",
      "30562,30562,76511,76530,5-17,15.307692307692308,2020-03-11,local\n",
      "30563,30563,76511,76530,50-64,16.884615384615387,2020-03-11,local\n"
     ]
    }
   ],
   "source": [
    "!head ../data/lccf/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c44cd-1629-4877-950b-c01f478c2921",
   "metadata": {},
   "source": [
    "We're going to need more than just cp rows. Specifically:\n",
    "- Census data probably needs unique `primaryKey == [GEOID, age_bin]`\n",
    "- Travel data needs n^2 rows where n is the number of GEOIDs\n",
    "\n",
    "So what we really mean by \"scaling rows\" is that we're scaling by `n`, number of GEOIDs in the census CSV. Easy way to do this is just prepend non-zero integer to GEOID.\n",
    "\n",
    "----\n",
    "\n",
    "## Parsers for each schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3873072-a66a-4b44-b780-df2d5c2f9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_census(csv_fp: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_fp, usecols=schemas['census']['usecols'])\n",
    "    assert not df.isna().any().any(), ('found null values in df', df.isna().any())\n",
    "    # df.rename(columns={'GEOID': 'vertex', 'age_bin': 'age_group'}, inplace=True)\n",
    "    # df.set_index(['vertex', 'age_group'], inplace=True)\n",
    "    # filter to zcta that we want to model in the simulation (vertex coords)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f7dfc09-8de5-4e69-8782-889ab95c3c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_contacts(csv_fp: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(csv_fp, usecols=schemas['contacts']['usecols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eefea24d-f91f-4501-81c7-4297297be7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_travel(csv_fp: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(csv_fp, usecols=schemas['travel']['usecols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4cf65b-3fdb-4006-a793-b7773bf97b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'census': {'glob': ['../data/lccf/census_pop1_rows1.csv'],\n",
      "            'keys': None,\n",
      "            'parser': <function parse_census at 0x7f837ce609d0>,\n",
      "            'usecols': ('GEOID', 'age_bin', 'group_pop'),\n",
      "            'value_col': None},\n",
      " 'contacts': {'glob': ['../data/lccf/contacts_pop1_rows1.csv'],\n",
      "              'keys': None,\n",
      "              'parser': <function parse_contacts at 0x7f837bb54d30>,\n",
      "              'usecols': ('age1', 'age2', 'daily_per_capita_contacts'),\n",
      "              'value_col': None},\n",
      " 'travel': {'glob': ['../data/lccf/travel_pop1_rows1.csv'],\n",
      "            'keys': None,\n",
      "            'parser': <function parse_travel at 0x7f837ba72a60>,\n",
      "            'usecols': ('source',\n",
      "                        'destination',\n",
      "                        'age',\n",
      "                        'n',\n",
      "                        'date',\n",
      "                        'destination_type'),\n",
      "            'value_col': None}}\n"
     ]
    }
   ],
   "source": [
    "for schema in schemas:\n",
    "    schemas[schema]['parser'] = globals()[f'parse_{schema}']\n",
    "pp(schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885da24-0976-4838-9af8-0cc34abb6523",
   "metadata": {},
   "source": [
    "## Generate unique GEOIDs for census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ba7f04e-17ee-4f8d-948a-338f699144be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_geoid(ref: pd.Series, n=None) -> pd.Series:\n",
    "    \"\"\"Returns a pd.Series with `n` unique GEOID-like integers.\n",
    "    Iterates over GEOIDs in `ref`, prepending positive integer\n",
    "    to generate unique IDs.\n",
    "    \"\"\"\n",
    "    ref_ids = ref.unique().astype(str)\n",
    "    n = n if n is not None else len(ref_ids)\n",
    "    prefix = 1\n",
    "    out = list()\n",
    "    while len(out) < n:\n",
    "        out.extend((f'{str(prefix)}{geoid}' for geoid in ref_ids))\n",
    "        prefix += 1\n",
    "    as_ser = pd.Series(out[:n]).astype(int)\n",
    "    assert as_ser.unique().all()\n",
    "    return as_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f96c431-342f-41f0-822b-b2fe8c12c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas['census']['keys'] = get_unique_geoid(parse_census('../data/lccf/census_pop1_rows1.csv')['GEOID'], n=1936)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d4f2b-1b7d-42e8-b180-f4e1a2109907",
   "metadata": {},
   "source": [
    "## Generate unique pairwise combinations of GEOIDs for travel data\n",
    "\n",
    "We assume the worst case scenario here: a length n^2 index for n GEOIDs. In reality, probably a few less, since the graph of travel between GEOIDs is not complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34b1d513-26fe-4d94-a6e1-86dfd4cdd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_pairs(geoids: pd.Series) -> pd.DataFrame\n",
    "    return geoids.to_frame(name='source').merge(geoids.to_frame(name='destination'), how='cross')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556150de-5d6c-4b31-aa13-b3ca5ca8542b",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8ab65ea-1226-4e2d-b2ac-401f9199f75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175001</td>\n",
       "      <td>175001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175001</td>\n",
       "      <td>175002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175001</td>\n",
       "      <td>175006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175001</td>\n",
       "      <td>175007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175001</td>\n",
       "      <td>175009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  destination\n",
       "0  175001       175001\n",
       "1  175001       175002\n",
       "2  175001       175006\n",
       "3  175001       175007\n",
       "4  175001       175009"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_pairs(schemas['census']['keys']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd59d0c-face-471a-a123-477d318fee8c",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9304c780-f453-4b2a-b663-d01b9533debd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         175001\n",
       "1         175002\n",
       "2         175006\n",
       "3         175007\n",
       "4         175009\n",
       "          ...   \n",
       "19364    1175028\n",
       "19365    1175032\n",
       "19366    1175034\n",
       "19367    1175035\n",
       "19368    1175038\n",
       "Length: 19369, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemas['census']['keys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49152be1-866a-456a-a042-69ac6ac682a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
