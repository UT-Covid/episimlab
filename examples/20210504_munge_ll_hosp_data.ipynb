{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0fabc90530c0b2a27e0e08c39e8896d95069f43881dee3af8511e14ee5c7ad9e5",
   "display_name": "Python 3.8.3 64-bit ('3.8.3': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "source": [
    "# 20210504_munge_ll_hosp_data\n",
    "\n",
    "The purpose of this notebook is to reformat the (local-only) hospitalization line list data in the file `data/CV19Hospital_ICU_DeID_20210414.csv`. **Important**: before committing this notebook, ensure to clear cell outputs, since these data should not be pushed to public cloud.\n",
    "\n",
    "Right now, data have the following schema:\n",
    "```csv\n",
    "ID,Age,Zip Code of Residence,Hospital,Date of Admission,ICU?,Ventilator?,Date of Discharge,Discharge Status,Occupation\n",
    "9999,99,99999,hosp1,2020-99-99,False,False,2020-99-99,HOSPICE - MEDICAL FACILITY 51,Retired\n",
    "9999,99,99999,hosp1,2020-99-99,False,False,2020-99-99,Expired 20,Retired\n",
    "9999,99,99999,hosp2,2020-99-99,False,False,2020-99-99,HOME,Resident\n",
    "9999,99,99999,hosp2,2020-99-99,False,False,2020-99-99,HOME,Construction and Extraction Occupations\n",
    "```\n",
    "\n",
    "And we want to transform into something like:\n",
    "```csv\n",
    "date,zip_code,hosp,deceased\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "----\n",
    "\n",
    "Convert to CSV: \n",
    "```\n",
    "in2csv data/CV19Hospital_ICU_DeID_20210414.xlsx > data/CV19Hospital_ICU_DeID_20210414.csv\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('../data/CV19Hospital_ICU_DeID_20210414.csv', parse_dates=True)"
   ]
  },
  {
   "source": [
    "Is it plausible to pull death data out of these? And fit to `Ih2D`?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['Discharge Status'].unique()"
   ]
  },
  {
   "source": [
    "Save this for later; there are way too many outcomes documented here that could be categorized as deaths."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    raw_df\n",
    "    [['ID', 'Zip Code of Residence', 'Date of Admission', 'Date of Discharge']]\n",
    "    .rename(columns={'ID': 'id', 'Zip Code of Residence': 'zip_code', 'Date of Admission': 'admission_date', 'Date of Discharge': 'discharge_date'})\n",
    "    # null admission discharge dates\n",
    "    .replace('No Discharge Date', np.nan)\n",
    ")"
   ]
  },
  {
   "source": [
    "Convert to datetimes:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['discharge_date'] = pd.to_datetime(df['discharge_date'], format=\"%Y-%m-%d\")\n",
    "df['admission_date'] = pd.to_datetime(df['admission_date'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "Next, use groupby objects to catalogue admission and discharge events, indexed by zip code and date:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = (\n",
    "    df\n",
    "    .rename(columns={'admission_date': 'date'})\n",
    "    .groupby(['zip_code', 'date'])\n",
    "    ['id']\n",
    "    .count()\n",
    ")\n",
    "discharges = (\n",
    "    df\n",
    "    .rename(columns={'discharge_date': 'date'})\n",
    "    .groupby(['zip_code', 'date'])\n",
    "    ['id']\n",
    "    .count()\n",
    ")\n",
    "delta = admissions.sub(discharges, fill_value=0.)\n",
    "delta.head()"
   ]
  },
  {
   "source": [
    "Calculate net change for each zip code. In theory, this should be zero:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 84 zip codes with unaccounted discharges out of 509 zip codes.\n217 unaccounted for discharges and 7942 accounted for discharges.\n"
     ]
    }
   ],
   "source": [
    "delta_per_zip = delta.groupby('zip_code').sum()\n",
    "# delta_per_zip\n",
    "with_unacc_dc = delta_per_zip[delta_per_zip > 0].count()\n",
    "unacc_dc = delta_per_zip[delta_per_zip > 0].sum().astype(int)\n",
    "acc_dc = -delta[delta < 0].sum().astype(int)\n",
    "print(f\"There are {with_unacc_dc} zip codes with unaccounted discharges out of {len(delta_per_zip.index)} zip codes.\")\n",
    "print(f\"{unacc_dc} unaccounted for discharges and {acc_dc} accounted for discharges.\")"
   ]
  },
  {
   "source": [
    "Any patterns at a glance for null discharge date rows?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df[df['discharge_date'].isnull()].head()"
   ]
  },
  {
   "source": [
    "Not really, this might mean deceased, but still gives us no information on date of discharge."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "What should we do about unaccounted for discharges? Possible solutions:\n",
    "- Set discharge date as max date\n",
    "    - Inflates Ih\n",
    "- Ignore admission and discharge for `id` with unaccounted discharge\n",
    "    - Deflates Ih\n",
    "- Calculate the mean hospital duration and use that to extrapolate a discharge date\n",
    "\n",
    "Will probably need to discuss with KP. Until then, take option #1, which is probably the easiest at this point, since it just means \"ignore any possible missed discharge events.\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "delta.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Need a continuous `date` index to assign to second MultiIndex level:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09',\n",
       "               '2020-03-10', '2020-03-11', '2020-03-12', '2020-03-13',\n",
       "               '2020-03-14', '2020-03-15',\n",
       "               ...\n",
       "               '2021-04-05', '2021-04-06', '2021-04-07', '2021-04-08',\n",
       "               '2021-04-09', '2021-04-10', '2021-04-11', '2021-04-12',\n",
       "               '2021-04-13', '2021-04-14'],\n",
       "              dtype='datetime64[ns]', length=405, freq='D')"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "cont_dt = pd.date_range(\n",
    "    start=delta.index.get_level_values(1).min(),\n",
    "    end=delta.index.get_level_values(1).max(), \n",
    "    freq='D'\n",
    ")\n",
    "cont_dt"
   ]
  },
  {
   "source": [
    "Annoyingly, `reindex` doesn't broadcast at second level in a MultiIndex:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta.reindex(cont_dt, level=1, fill_value=0., copy=True)"
   ]
  },
  {
   "source": [
    "...but it works fine when there's only a single index:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta['10029'].reindex(cont_dt, fill_value=0., copy=True)"
   ]
  },
  {
   "source": [
    "One workaround is to reindex direclty using a MultiIndex: https://stackoverflow.com/questions/53286882/how-to-reindex-a-multiindex-dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_midx = pd.MultiIndex.from_product(\n",
    "    [delta.index.levels[0], cont_dt],\n",
    "    names=['zip_code', 'date'])\n",
    "ih = delta.reindex(cont_midx, fill_value=0., copy=True)\n",
    "# remove 'Unknown' zip code\n",
    "del ih['Unknown']"
   ]
  },
  {
   "source": [
    "_TODO_: see if we can do this in Dask, since this workflow isn't that scalable in pandas alone."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ih"
   ]
  },
  {
   "source": [
    "## Convert to DataArray and Write to Zarr\n",
    "\n",
    "Let's convert to an `xarray.DataArray` and write it to a zarr archive, in the same folder (`../data`):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ih_da = xr.DataArray.from_series(ih)\n",
    "ih_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.6M\t../data/CV19Hospital_ICU_DeID_20210414.nc\n"
     ]
    }
   ],
   "source": [
    "ih_da.to_netcdf('../data/CV19Hospital_ICU_DeID_20210414.nc')\n",
    "!du -hs '../data/CV19Hospital_ICU_DeID_20210414.nc'"
   ]
  }
 ]
}